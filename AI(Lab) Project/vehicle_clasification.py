# -*- coding: utf-8 -*-
"""Vehicle_Clasification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oOcVVPzKzOO5rfLtNniaZzKDJEwZjcLX
"""

from google.colab import drive

# Mount Google Drive
drive.mount('/content/gdrive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from shutil import copyfile
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.naive_bayes import BernoulliNB
import cv2
import random
from tensorflow.keras import layers
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.applications import Xception
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from skimage import io
from sklearn.metrics import ConfusionMatrixDisplay
import seaborn as sns
import os
for dirname, _, filenames in os.walk('/content/gdrive'):
      print(dirname)

# size of each categories
print(len(os.listdir('/content/gdrive/My Drive/Dataset/Auto')))
print(len(os.listdir('/content/gdrive/My Drive/Dataset/Car')))
print(len(os.listdir('/content/gdrive/My Drive/Dataset/Motorcycle')))

import os

# Specify the directory path
directory_path1 = '/content/gdrive/My Drive/training'
directory_path2 = '/content/gdrive/My Drive/validation'
# Use os.makedirs with exist_ok=True to create the directory if it doesn't exist
os.makedirs(directory_path1, exist_ok=True)
os.makedirs(directory_path2, exist_ok=True)

try:
    classes = ['Auto','Car','Motorcycle']
    for class_name in classes:
        os.mkdir(os.path.join('/content/gdrive/My Drive/training',class_name))
        os.mkdir(os.path.join('/content/gdrive/My Drive/validation',class_name))
        print('created')
# if directory already exist
except:
    print('failed')

from shutil import copyfile

def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):
    data = []

    for file_name in os.listdir(SOURCE):
        file_path = os.path.join(SOURCE, file_name)

        # Check if the file exists and has a size greater than 0
        if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
            data.append(file_name)

    LENGTH = int(len(data) * SPLIT_SIZE)

    # Split the data into training and testing sets
    train_data = data[:LENGTH]
    test_data = data[LENGTH:]

    # Copy files to training directory
    for i in train_data:
        copyfile(os.path.join(SOURCE, i), os.path.join(TRAINING, i))

    # Copy files to testing directory
    for i in test_data:
        copyfile(os.path.join(SOURCE, i), os.path.join(TESTING, i))

# directory paths
Auto_SOURCE_DIR = '/content/gdrive/My Drive/Dataset/Auto/'
TRAINING_Auto_DIR = '/content/gdrive/My Drive/training/Auto/'
TESTING_Auto_DIR = '/content/gdrive/My Drive/validation/Auto/'

Car_SOURCE_DIR = '/content/gdrive/My Drive/Dataset/Car/'
TRAINING_Car_DIR = '/content/gdrive/My Drive/training/Car/'
TESTING_Car_DIR = '/content/gdrive/My Drive/validation/Car/'

Motorcycle_SOURCE_DIR = '/content/gdrive/My Drive/Dataset/Motorcycle/'
TRAINING_Motorcycle_DIR = '/content/gdrive/My Drive/training/Motorcycle/'
TESTING_Motorcycle_DIR = '/content/gdrive/My Drive/validation/Motorcycle/'

# split size
split_size = 0.8

split_data(Auto_SOURCE_DIR, TRAINING_Auto_DIR, TESTING_Auto_DIR, split_size)
split_data(Car_SOURCE_DIR, TRAINING_Car_DIR, TESTING_Car_DIR, split_size)
split_data(Motorcycle_SOURCE_DIR, TRAINING_Motorcycle_DIR, TESTING_Motorcycle_DIR, split_size)

# for Auto class
for img in os.listdir('/content/gdrive/My Drive/Dataset/Auto/'):
  path_img = os.path.join('/content/gdrive/My Drive/Dataset/Auto/',img)
  image = io.imread(path_img)
  i, (im1, im2, im3, im4) = plt.subplots(1, 4, sharey=True)
  i.set_figwidth(20)

  im1.imshow(image)  #Original image
  im2.imshow(image[:, : , 0]) #Red
  im3.imshow(image[:, : , 1]) #Green
  im4.imshow(image[:, : , 2]) #Blue
  i.suptitle('Original & RGB image channels')
  break

# for car class
for img in os.listdir('/content/gdrive/My Drive/Dataset/Car/'):
  path_img = os.path.join('/content/gdrive/My Drive/Dataset/Car/',img)
  image = io.imread(path_img)
  i, (im1, im2, im3, im4) = plt.subplots(1, 4, sharey=True)
  i.set_figwidth(20)

  im1.imshow(image)  #Original image
  im2.imshow(image[:, : , 0]) #Red
  im3.imshow(image[:, : , 1]) #Green
  im4.imshow(image[:, : , 2]) #Blue
  i.suptitle('Original & RGB image channels')
  break
# for motorcycle class
for img in os.listdir('/content/gdrive/My Drive/Dataset/Motorcycle/'):
  path_img = os.path.join('/content/gdrive/My Drive/Dataset/Motorcycle/',img)
  image = io.imread(path_img)
  i, (im1, im2, im3, im4) = plt.subplots(1, 4, sharey=True)
  i.set_figwidth(20)

  im1.imshow(image)  #Original image
  im2.imshow(image[:, : , 0]) #Red
  im3.imshow(image[:, : , 1]) #Green
  im4.imshow(image[:, : , 2]) #Blue
  i.suptitle('Original & RGB image channels')
  break

# data augmentation

train_datagen = ImageDataGenerator(rescale=1/255.,
                                   rotation_range = 40,
                                   width_shift_range =0.2,
                                   height_shift_range = 0.2,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip= True)

train_generator = train_datagen.flow_from_directory(directory='/content/gdrive/My Drive/training/',
                                             target_size=(150,150),
                                             color_mode = 'rgb',
                                             class_mode='categorical',
                                             batch_size=100,
                                             shuffle = True,
                                             seed =42)

validation_datagen = ImageDataGenerator(rescale=1/255.)

validation_generator = validation_datagen.flow_from_directory(directory='/content/gdrive/My Drive/validation',
                                             target_size=(150,150),
                                             color_mode='rgb',
                                             class_mode='categorical',
                                             batch_size=100,
                                             shuffle = True,
                                             seed =42)
# training set and validation set
X_train, y_train = next(train_generator)
X_valid , y_valid = next(validation_generator)

import os
import numpy as np
from keras.preprocessing import image
from keras.models import Sequential
from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten
from keras.applications import Xception
from keras import layers
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
#feature extracting from cnn model
model = Sequential()
model.add(Xception(weights = 'imagenet', input_shape = (150,150,3),include_top=False))
model.add(layers.GlobalAveragePooling2D())
model.add(layers.Dense(512,activation = 'relu', name ='fc1'))
model.add(layers.Dense(512,activation = 'relu', name ='fc2'))
model.add(layers.Dense(512,activation = 'relu', name ='fc3'))
model.add(layers.Dense(256,activation = 'relu', name ='fc4'))
model.add(layers.Dropout(0.1))
model.add(layers.Flatten())
model.add(layers.Dense(3,activation='softmax',name = 'fc5'))

model.layers[0].trainable=False
model.compile(loss= 'categorical_crossentropy',optimizer= 'adam',metrics = ['accuracy'])
model.summary()
model.fit(train_generator,
          epochs=10,
          verbose = 1,
          validation_data = validation_generator)

import numpy as np
from keras.preprocessing import image
import matplotlib.pyplot as plt

def load_and_predict(image_path, model, validation_generator):
    # Load and preprocess the image
    img = image.load_img(image_path, target_size=(150, 150))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Rescale to [0, 1]

    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)

    true_class = validation_generator.classes[validation_generator.filepaths.index(image_path)]

    class_labels = list(validation_generator.class_indices.keys())

    actual_class = class_labels[true_class]

    plt.figure(figsize=(6, 6))
    plt.imshow(img)
    plt.title(f"Actual: {actual_class}, Predicted: {class_labels[predicted_class]}")
    plt.axis("off")
    plt.show()

    return actual_class, class_labels[predicted_class], prediction[0][predicted_class]

test_image_paths = [
    '/content/gdrive/My Drive/validation/Motorcycle/0700.jpg',
    '/content/gdrive/My Drive/validation/Auto/746 1.09.21 PM.jpg',
    '/content/gdrive/My Drive/validation/Car/07334.jpg'
    ]

for test_image_path in test_image_paths:
    print(f"Processing image: {test_image_path}")
    actual_class, predicted_class, validation_accuracy = load_and_predict(test_image_path, model, validation_generator)

    print(f"Actual Class: {actual_class}")
    print(f"Predicted Class: {predicted_class}")
    print(f"Validation Accuracy: {validation_accuracy}")
    print("===")

from sklearn.metrics import classification_report

# Get predictions from the model
y_pred = model.predict(X_valid)

# Convert predictions to class labels
y_pred_labels = np.argmax(y_pred, axis=1)

# Get true labels
y_true_labels = np.argmax(y_valid, axis=1)

# classification report
report = classification_report(y_true_labels, y_pred_labels, target_names=['Auto', 'Car', 'Motorcycle'])

# Print the classification report
print(report)

from keras.preprocessing.image import ImageDataGenerator

# Set the path to the test directory
test_dir = '/content/gdrive/My Drive/validation'

# Create a test data generator
test_datagen = ImageDataGenerator(rescale=1/255.)
test_generator = test_datagen.flow_from_directory(
    directory=test_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

# Check the length of the test generator
if len(test_generator) == 0:
    print("No images found in the test directory.")
else:
    # Evaluate the model on the test set
    test_loss, test_accuracy = model.evaluate(test_generator)
    print(f'Test Loss: {test_loss:.4f}')
    print(f'Test Accuracy: {test_accuracy:.4f}')
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Generate predictions from the model on the test set
y_pred_prob = model.predict(test_generator)
y_pred = np.argmax(y_pred_prob, axis=1)

# Get true labels
y_true = test_generator.classes

# Get class labels
class_labels = list(test_generator.class_indices.keys())

# Plot confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

print(f'Test Loss: {test_loss:.4f}')
print(f'Test Accuracy: {test_accuracy:.4f}')

history = model.fit(train_generator, epochs=5, validation_data=validation_generator, verbose=1)

# Plot training history
plt.figure(figsize=(12, 4))

# Plot training & validation accuracy values
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.show()
print(f'Test Loss: {test_loss:.4f}')
print(f'Test Accuracy: {test_accuracy:.4f}')